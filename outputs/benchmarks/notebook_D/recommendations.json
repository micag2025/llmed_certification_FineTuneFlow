{
  "BART-large": {
    "size_hint": "0.4B",
    "method": "LoRA (PEFT) \u2014 encoder\u2013decoder friendly",
    "recommended_hyperparams": {
      "epochs": 3,
      "micro_batch_size": 8,
      "lr": 0.0002
    }
  },
  "LLaMA-1B": {
    "size_hint": "1B",
    "method": "LoRA or full fine-tune",
    "recommended_hyperparams": {
      "epochs": 3,
      "micro_batch_size": 8,
      "lr": 0.0002
    }
  }
}