{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rGHxZTSakB_x",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hLoaded final ranking:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"print(\\\"Files:\\\\n \\\", \\\"\\\\n \\\"\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"meta-llama/Llama-3.2-1B-Instruct\",\n          \"t5-large\",\n          \"meta-llama/Llama-3.2-3B-Instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.197540545985215,\n        \"min\": 10.977281761408957,\n        \"max\": 28.63587425572817,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          28.63587425572817,\n          10.977281761408957,\n          23.77179257823773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.101704601687299,\n        \"min\": 1.9440093037647928,\n        \"max\": 9.618124519432426,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          9.618124519432426,\n          1.9440093037647928,\n          8.222793347601673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.881426094408252,\n        \"min\": 9.636944068641258,\n        \"max\": 21.20538749371836,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          21.20538749371836,\n          9.636944068641258,\n          17.30620340596481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 362.45749717977753,\n        \"min\": 101.63183641433716,\n        \"max\": 987.636198759079,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          393.9294948577881,\n          263.02784180641174,\n          748.2234883308411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"throughput\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7201431081377652,\n        \"min\": 0.2025037156913559,\n        \"max\": 1.967887298470444,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5077050655275298,\n          0.7603757785732805,\n          0.2672998149873186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"efficiency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07975915798730274,\n        \"min\": 0.0144857759904863,\n        \"max\": 0.2072444685200989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0538304132351747,\n          0.0366384942463012,\n          0.0231297248427364\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"composite_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.866576615173311,\n        \"min\": -0.9599622636932412,\n        \"max\": 1.230693974550218,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4632295061715081,\n          -0.9599622636932412,\n          -0.1623421422954028\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-51727ccb-ca86-4f62-9dc7-d20f4ba4c043\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "      <th>throughput</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BART-large</th>\n",
       "      <td>facebook/bart-large-cnn</td>\n",
       "      <td>28.105383</td>\n",
       "      <td>9.183429</td>\n",
       "      <td>21.062636</td>\n",
       "      <td>101.631836</td>\n",
       "      <td>1.967887</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>1.230694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-1B</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>28.635874</td>\n",
       "      <td>9.618125</td>\n",
       "      <td>21.205387</td>\n",
       "      <td>393.929495</td>\n",
       "      <td>0.507705</td>\n",
       "      <td>0.053830</td>\n",
       "      <td>0.463230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-3B</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>23.771793</td>\n",
       "      <td>8.222793</td>\n",
       "      <td>17.306203</td>\n",
       "      <td>748.223488</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>-0.162342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-Mini</th>\n",
       "      <td>microsoft/Phi-3-mini-4k-instruct</td>\n",
       "      <td>20.550442</td>\n",
       "      <td>7.028457</td>\n",
       "      <td>14.306677</td>\n",
       "      <td>987.636199</td>\n",
       "      <td>0.202504</td>\n",
       "      <td>0.014486</td>\n",
       "      <td>-0.571619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5-large</th>\n",
       "      <td>t5-large</td>\n",
       "      <td>10.977282</td>\n",
       "      <td>1.944009</td>\n",
       "      <td>9.636944</td>\n",
       "      <td>263.027842</td>\n",
       "      <td>0.760376</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>-0.959962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51727ccb-ca86-4f62-9dc7-d20f4ba4c043')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-51727ccb-ca86-4f62-9dc7-d20f4ba4c043 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-51727ccb-ca86-4f62-9dc7-d20f4ba4c043');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-8684e458-858a-40a5-94ac-ef5666b38de4\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8684e458-858a-40a5-94ac-ef5666b38de4')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-8684e458-858a-40a5-94ac-ef5666b38de4 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                    model_id     rouge1    rouge2     rougeL  \\\n",
       "BART-large           facebook/bart-large-cnn  28.105383  9.183429  21.062636   \n",
       "LLaMA-1B    meta-llama/Llama-3.2-1B-Instruct  28.635874  9.618125  21.205387   \n",
       "LLaMA-3B    meta-llama/Llama-3.2-3B-Instruct  23.771793  8.222793  17.306203   \n",
       "Phi-3-Mini  microsoft/Phi-3-mini-4k-instruct  20.550442  7.028457  14.306677   \n",
       "T5-large                            t5-large  10.977282  1.944009   9.636944   \n",
       "\n",
       "                  time  throughput  efficiency  composite_score  \n",
       "BART-large  101.631836    1.967887    0.207244         1.230694  \n",
       "LLaMA-1B    393.929495    0.507705    0.053830         0.463230  \n",
       "LLaMA-3B    748.223488    0.267300    0.023130        -0.162342  \n",
       "Phi-3-Mini  987.636199    0.202504    0.014486        -0.571619  \n",
       "T5-large    263.027842    0.760376    0.036638        -0.959962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU mem (GB): 15.828320256\n",
      "\n",
      "Top selected models:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"top_models\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"meta-llama/Llama-3.2-1B-Instruct\",\n          \"facebook/bart-large-cnn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3751142202454468,\n        \"min\": 28.10538263801805,\n        \"max\": 28.63587425572817,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          28.63587425572817,\n          28.10538263801805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30737620510600716,\n        \"min\": 9.183428921420736,\n        \"max\": 9.618124519432426,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9.618124519432426,\n          9.183428921420736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10094060409651018,\n        \"min\": 21.06263592241094,\n        \"max\": 21.20538749371836,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          21.20538749371836,\n          21.06263592241094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206.68565641031347,\n        \"min\": 101.63183641433716,\n        \"max\": 393.9294948577881,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          393.9294948577881,\n          101.63183641433716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"throughput\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0325047586820497,\n        \"min\": 0.5077050655275298,\n        \"max\": 1.967887298470444,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5077050655275298,\n          1.967887298470444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"efficiency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1084801188212978,\n        \"min\": 0.0538304132351747,\n        \"max\": 0.2072444685200989,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0538304132351747,\n          0.2072444685200989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"composite_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5426793299103144,\n        \"min\": 0.4632295061715081,\n        \"max\": 1.230693974550218,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4632295061715081,\n          1.230693974550218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_hint\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1B\",\n          \"0.4B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "top_models"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ddd32870-aa70-41ec-929b-c6b89cb31752\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "      <th>throughput</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>size_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BART-large</th>\n",
       "      <td>facebook/bart-large-cnn</td>\n",
       "      <td>28.105383</td>\n",
       "      <td>9.183429</td>\n",
       "      <td>21.062636</td>\n",
       "      <td>101.631836</td>\n",
       "      <td>1.967887</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>1.230694</td>\n",
       "      <td>0.4B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-1B</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>28.635874</td>\n",
       "      <td>9.618125</td>\n",
       "      <td>21.205387</td>\n",
       "      <td>393.929495</td>\n",
       "      <td>0.507705</td>\n",
       "      <td>0.053830</td>\n",
       "      <td>0.463230</td>\n",
       "      <td>1B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd32870-aa70-41ec-929b-c6b89cb31752')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ddd32870-aa70-41ec-929b-c6b89cb31752 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ddd32870-aa70-41ec-929b-c6b89cb31752');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-584b4f46-f0e3-46b0-af93-74a613f987b1\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-584b4f46-f0e3-46b0-af93-74a613f987b1')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-584b4f46-f0e3-46b0-af93-74a613f987b1 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_2e1c89f8-918d-4da3-a9e4-e91039c4cbbd\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_models')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_2e1c89f8-918d-4da3-a9e4-e91039c4cbbd button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('top_models');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                    model_id     rouge1    rouge2     rougeL  \\\n",
       "BART-large           facebook/bart-large-cnn  28.105383  9.183429  21.062636   \n",
       "LLaMA-1B    meta-llama/Llama-3.2-1B-Instruct  28.635874  9.618125  21.205387   \n",
       "\n",
       "                  time  throughput  efficiency  composite_score size_hint  \n",
       "BART-large  101.631836    1.967887    0.207244         1.230694      0.4B  \n",
       "LLaMA-1B    393.929495    0.507705    0.053830         0.463230        1B  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úî Fine-tuning plan written to /content/llmed_certification_FineTuneFlow/outputs/benchmarks/notebook_D_pro/finetune_plan_pro_20251202_123700.md\n",
      "\n",
      "üìÅ Outputs written to: /content/llmed_certification_FineTuneFlow/outputs/benchmarks/notebook_D_pro\n",
      "Files:\n",
      "  finetune_plan_pro_20251202_123700.md\n",
      " recommendations_pro_20251202_123700.json\n",
      " train_lora_BART-large_20251202_123700.py\n",
      " train_q_lora_LLaMA-1B_20251202_123700.py\n"
     ]
    }
   ],
   "source": [
    "# Pro-level Notebook D (model-aware templates & GPU checks)\n",
    "# More robust: model-aware prompts, GPU memory check, BitsAndBytes import, target module heuristics.\n",
    "\n",
    "!pip install -q pandas transformers bitsandbytes peft\n",
    "\n",
    "import os, json, datetime, torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from textwrap import dedent\n",
    "\n",
    "# -------------------------\n",
    "# Config / Paths\n",
    "# -------------------------\n",
    "FINAL_CSV = \"/content/llmed_certification_FineTuneFlow/outputs/benchmarks/notebook_C/final_ranking.csv\"\n",
    "OUT_DIR = \"/content/llmed_certification_FineTuneFlow/outputs/benchmarks/notebook_D_pro\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(FINAL_CSV):\n",
    "    raise FileNotFoundError(f\"Cannot find merged ranking CSV at {FINAL_CSV}. Run Notebook C first.\")\n",
    "\n",
    "df = pd.read_csv(FINAL_CSV, index_col=0)\n",
    "print(\"Loaded final ranking:\")\n",
    "display(df.head())\n",
    "\n",
    "# -------------------------\n",
    "# Improved size map & infer\n",
    "# -------------------------\n",
    "size_hints = {\n",
    "    \"bart-large\": \"0.4B\",\n",
    "    \"bart\": \"0.4B\",\n",
    "    \"t5-large\": \"0.8B\",\n",
    "    \"t5\": \"0.8B\",\n",
    "    \"llama-1b\": \"1B\",\n",
    "    \"llama-3b\": \"3B\",\n",
    "    \"llama\": \"3B\",\n",
    "    \"phi-3-mini\": \"4B\",\n",
    "    \"phi\": \"4B\",\n",
    "}\n",
    "\n",
    "def infer_model_size(model_name):\n",
    "    key = model_name.lower().replace(\"/\", \"-\")\n",
    "    for k, v in size_hints.items():\n",
    "        if k in key:\n",
    "            return v\n",
    "    return \"unknown\"\n",
    "\n",
    "df[\"size_hint\"] = df.index.map(infer_model_size)\n",
    "\n",
    "# -------------------------\n",
    "# Detect GPU mem (if available)\n",
    "# -------------------------\n",
    "def get_gpu_mem_gb():\n",
    "    try:\n",
    "        if not torch.cuda.is_available():\n",
    "            return None\n",
    "        prop = torch.cuda.get_device_properties(0)\n",
    "        return prop.total_memory / 1e9\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "gpu_mem = get_gpu_mem_gb()\n",
    "print(\"Detected GPU mem (GB):\", gpu_mem)\n",
    "\n",
    "# -------------------------\n",
    "# Model-aware recommendation logic\n",
    "# -------------------------\n",
    "def recommend_method(model_name, size_hint, gpu_mem_gb=None):\n",
    "    ln = model_name.lower()\n",
    "    if \"bart\" in ln or \"t5\" in ln:\n",
    "        return \"LoRA (PEFT) ‚Äî encoder‚Äìdecoder friendly\"\n",
    "\n",
    "    try:\n",
    "        gb = float(size_hint.replace(\"b\",\"\").replace(\"B\",\"\").strip())\n",
    "    except:\n",
    "        return \"QLoRA (recommended) / manual check\"\n",
    "\n",
    "    # refine by gpu_mem if known\n",
    "    if gpu_mem_gb is not None:\n",
    "        if gb <= 3 and gpu_mem_gb >= 24:\n",
    "            return \"LoRA or QLoRA (both possible on >=24GB)\"\n",
    "        if gb <= 4.5 and gpu_mem_gb >= 40:\n",
    "            return \"QLoRA (4-bit) on local GPU\"\n",
    "        if gb > 6 and gpu_mem_gb < 40:\n",
    "            return \"Hosted fine-tuning / QLoRA on A100/H100\"\n",
    "\n",
    "    # fallback rules\n",
    "    if gb <= 1.5:\n",
    "        return \"LoRA or full fine-tune\"\n",
    "    if gb <= 4.5:\n",
    "        return \"QLoRA (4-bit) ‚Äî use local or cloud with >=40GB\"\n",
    "    if gb <= 8:\n",
    "        return \"QLoRA (4-bit) ‚Äî GPU with >=40GB recommended\"\n",
    "    return \"Hosted fine-tuning / QLoRA on A100/H100\"\n",
    "\n",
    "def hyperparams_suggestion(model_name, size_hint):\n",
    "    ln = model_name.lower()\n",
    "    try:\n",
    "        gb = float(size_hint.replace(\"b\",\"\").replace(\"B\",\"\").strip())\n",
    "    except:\n",
    "        gb = 3.0\n",
    "    # model-aware tweaks\n",
    "    if \"t5\" in ln:\n",
    "        base_lr = 2e-4\n",
    "    else:\n",
    "        base_lr = 1e-4\n",
    "\n",
    "    if gb <= 1.5:\n",
    "        return {\"epochs\": 3, \"micro_batch_size\": 8, \"lr\": base_lr}\n",
    "    if gb <= 4.5:\n",
    "        return {\"epochs\": 3, \"micro_batch_size\": 4, \"lr\": base_lr / 2}\n",
    "    if gb <= 8:\n",
    "        return {\"epochs\": 3, \"micro_batch_size\": 1, \"lr\": base_lr / 2}\n",
    "    return {\"epochs\": 2, \"micro_batch_size\": 1, \"lr\": base_lr / 5}\n",
    "\n",
    "# -------------------------\n",
    "# Top-K and recommendations\n",
    "# -------------------------\n",
    "TOP_K = 2\n",
    "top_models = df.sort_values(\"composite_score\", ascending=False).head(TOP_K)\n",
    "print(\"\\nTop selected models:\")\n",
    "display(top_models)\n",
    "\n",
    "recommendations = {}\n",
    "for model in top_models.index:\n",
    "    size_hint = infer_model_size(model)\n",
    "    method = recommend_method(model, size_hint, gpu_mem)\n",
    "    hps = hyperparams_suggestion(model, size_hint)\n",
    "    recommendations[model] = {\n",
    "        \"size_hint\": size_hint,\n",
    "        \"method\": method,\n",
    "        \"recommended_hyperparams\": hps,\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Model-aware prompt templates and target module heuristics\n",
    "# -------------------------\n",
    "def prompt_template_for_model(model_name):\n",
    "    ln = model_name.lower()\n",
    "    if \"llama\" in ln or \"meta-llama\" in ln:\n",
    "        return lambda text: f\"[INST] Summarize the conversation:\\n{text} [/INST]\"\n",
    "    if \"phi\" in ln or \"microsoft\" in ln:\n",
    "        return lambda text: f\"<|system|>Summarize the conversation.<|end|>\\\\n{text}\\\\n<|assistant|>\"\n",
    "    if \"t5\" in ln or \"flan\" in ln:\n",
    "        return lambda text: f\"summarize: {text}\"\n",
    "    return lambda text: text\n",
    "\n",
    "def guess_target_modules(model_name):\n",
    "    ln = model_name.lower()\n",
    "    # conservative defaults\n",
    "    if \"t5\" in ln or \"bart\" in ln:\n",
    "        return [\"q_proj\", \"v_proj\"]\n",
    "    if \"llama\" in ln or \"phi\" in ln:\n",
    "        return [\"q_proj\", \"v_proj\"]\n",
    "    return [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "# -------------------------\n",
    "# Write plan + scripts with improved safety\n",
    "# -------------------------\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "plan_lines = [\"# Fine-tuning Plan (Auto-Generated)\", \"\", f\"Generated: {timestamp}\", \"\"]\n",
    "\n",
    "for i, (name, row) in enumerate(top_models.iterrows(), start=1):\n",
    "    rec = recommendations[name]\n",
    "    plan_lines.append(f\"### {i}. {name}\")\n",
    "    plan_lines.append(f\"- Composite score: {row.get('composite_score', 0):.4f}\")\n",
    "    plan_lines.append(f\"- ROUGE-L: {row.get('rougeL', 0):.2f}%\")\n",
    "    plan_lines.append(f\"- Inferred size: {rec['size_hint']}\")\n",
    "    plan_lines.append(f\"- Detected GPU mem (GB): {gpu_mem}\")\n",
    "    plan_lines.append(f\"- Recommended method: **{rec['method']}**\")\n",
    "    plan_lines.append(f\"- Hyperparameters: `{rec['recommended_hyperparams']}`\")\n",
    "    plan_lines.append(\"\")\n",
    "\n",
    "plan_path = Path(OUT_DIR) / f\"finetune_plan_pro_{timestamp}.md\"\n",
    "with plan_path.open(\"w\") as f:\n",
    "    f.write(\"\\n\".join(plan_lines))\n",
    "\n",
    "print(f\"\\n‚úî Fine-tuning plan written to {plan_path}\")\n",
    "\n",
    "# templates for scripts (similar to Option 1 but with BitsAndBytes import and prompt usage)\n",
    "from textwrap import indent\n",
    "\n",
    "def make_lora_script(model_id, data_path, out_dir, target_modules, hps):\n",
    "    return dedent(f\"\"\"\\\n",
    "    # Auto-generated LoRA script (encoder-decoder)\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    MODEL = \"{model_id}\"\n",
    "    DATASET_PATH = \"{data_path}\"\n",
    "    OUTPUT_DIR = \"{out_dir}\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    lora_cfg = LoraConfig(r=8, lora_alpha=32, target_modules={target_modules}, lora_dropout=0.05)\n",
    "    model = get_peft_model(model, lora_cfg)\n",
    "\n",
    "    ds = load_dataset(\"json\", data_files={{\"train\": DATASET_PATH}})[\"train\"]\n",
    "\n",
    "    def tokenize_fn(example):\n",
    "        out = tokenizer(example[\"dialogue\"], truncation=True, max_length=768)\n",
    "        labels = tokenizer(example[\"summary\"], truncation=True, max_length=192).input_ids\n",
    "        out[\"labels\"] = labels\n",
    "        return out\n",
    "\n",
    "    train_ds = ds.map(tokenize_fn, remove_columns=ds.column_names)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        per_device_train_batch_size={hps['micro_batch_size']},\n",
    "        num_train_epochs={hps['epochs']},\n",
    "        learning_rate={hps['lr']},\n",
    "        fp16=True,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=train_ds)\n",
    "    trainer.train()\n",
    "    model.save_pretrained(OUTPUT_DIR)\n",
    "    \"\"\")\n",
    "\n",
    "def make_q_lora_script(model_id, data_path, out_dir, target_modules, hps):\n",
    "    return dedent(f\"\"\"\\\n",
    "    # Auto-generated QLoRA script (decoder-only)\n",
    "    import transformers\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "    from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    MODEL = \"{model_id}\"\n",
    "    DATASET_PATH = \"{data_path}\"\n",
    "    OUTPUT_DIR = \"{out_dir}\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    bnb = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\", quantization_config=bnb)\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    lora_cfg = LoraConfig(r=8, lora_alpha=32, target_modules={target_modules}, lora_dropout=0.05)\n",
    "    model = get_peft_model(model, lora_cfg)\n",
    "\n",
    "    ds = load_dataset(\"json\", data_files={{\"train\": DATASET_PATH}})[\"train\"]\n",
    "\n",
    "    def tokenize_fn(example):\n",
    "        prompt = example.get(\"prompt\", example[\"dialogue\"])\n",
    "        tok = tokenizer(prompt, truncation=True, max_length=768)\n",
    "        labels = tokenizer(example[\"summary\"], truncation=True, max_length=192).input_ids\n",
    "        tok[\"labels\"] = labels\n",
    "        return tok\n",
    "\n",
    "    train_ds = ds.map(tokenize_fn, remove_columns=ds.column_names)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        per_device_train_batch_size={hps['micro_batch_size']},\n",
    "        num_train_epochs={hps['epochs']},\n",
    "        learning_rate={hps['lr']},\n",
    "        fp16=True,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=train_ds)\n",
    "    trainer.train()\n",
    "    model.save_pretrained(OUTPUT_DIR)\n",
    "    \"\"\")\n",
    "\n",
    "# Emit scripts\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "DATASET_PATH = \"./highlightsum_train.jsonl\"\n",
    "for model in top_models.index:\n",
    "    rec = recommendations[model]\n",
    "    target_modules = guess_target_modules(model)\n",
    "    hps = rec[\"recommended_hyperparams\"]\n",
    "    outdir = f\"./ft_outputs/{model.replace('/', '_')}_{timestamp}\"\n",
    "    if \"LoRA\" in rec[\"method\"] and (\"encoder\" in rec[\"method\"].lower() or \"encoder\" in rec[\"method\"]):\n",
    "        content = make_lora_script(model, DATASET_PATH, outdir, target_modules, hps)\n",
    "        fname = Path(OUT_DIR) / f\"train_lora_{model.replace('/', '_')}_{timestamp}.py\"\n",
    "    else:\n",
    "        content = make_q_lora_script(model, DATASET_PATH, outdir, target_modules, hps)\n",
    "        fname = Path(OUT_DIR) / f\"train_q_lora_{model.replace('/', '_')}_{timestamp}.py\"\n",
    "    with open(fname, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Save metadata\n",
    "with open(Path(OUT_DIR) / f\"recommendations_pro_{timestamp}.json\", \"w\") as f:\n",
    "    json.dump(recommendations, f, indent=2)\n",
    "\n",
    "print(\"\\nüìÅ Outputs written to:\", OUT_DIR)\n",
    "print(\"Files:\\n \", \"\\n \".join(sorted(os.listdir(OUT_DIR))))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
